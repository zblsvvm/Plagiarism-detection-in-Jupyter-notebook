{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "15918efe959c5064d1d40a451606eb41",
     "grade": false,
     "grade_id": "cell-0867630144920503",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# <center>L2 Computational Physics</center>\n",
    "---\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "In this notebook, you shall illustrate the different behaviours of the gradient descent (GD) method when finding the minima of \n",
    "*Rosenbrock's Banana Function*,\n",
    "\n",
    "$$f(x,y) \\equiv (1-x)^{2} + 100(y-x^{2})^{2}~.$$\n",
    "\n",
    "You will generate a plot demonstrating how the behaviour of the GD method changes with different values of the step-size parameter, $\\eta$. To do this, you will plot example GD trajectories using three different $\\eta$ values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.colors\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4c48333235d0e6bb1bfdfd7129d23b29",
     "grade": false,
     "grade_id": "cell-465afe4059d95ac2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "First, define the functions `f` and `grad` which implement the *banana* function and its **analytical** derivative. \n",
    "`r` is a two component array of coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "38294af7dc6f858dc7612cd0f0d14f54",
     "grade": false,
     "grade_id": "banana",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def f(r):\n",
    "    '''Function to be minimised'''\n",
    "    x, y = r\n",
    "    return (1-x)**2 + 100*(y-x**2)**2;\n",
    "    \n",
    "    \n",
    "def grad(r):\n",
    "    '''Calculate gradient of banana function at coordinates r = (x,y)'''\n",
    "    x, y = r\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c715b9ab376634e44a6af3fea25b8d1",
     "grade": false,
     "grade_id": "cell-94963473700b2307",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Before proceeding, ensure that your functions have been written correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b80433b0eaeea723dd99d5614d396b",
     "grade": true,
     "grade_id": "banana_test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# these tests are worth 2 marks \n",
    "r = numpy.array([1, 4])\n",
    "assert numpy.isclose(f(r), 900)\n",
    "assert numpy.isclose(grad(r), numpy.array([-1200,   600])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the function `gradientDescent`. It takes as argument:\n",
    "\n",
    "- `df`: the derivative of the the function you want to minimize\n",
    "- `r0`: an array of two initial values where the algorithm starts\n",
    "- `eta`: the step size\n",
    "- `nstep`: the number of steps\n",
    "\n",
    "It should return the history of points visited, including the initial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b31972ef000809a72f775d9786312f8",
     "grade": false,
     "grade_id": "GD",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gradientDescent(df, r0, eta, nstep):\n",
    "    xy = r0\n",
    "    history = numpy.empty( (nstep+1, 2) )\n",
    "    # YOUR CODE HERE\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab1b4e9314278a498ae24e58db29a9a",
     "grade": false,
     "grade_id": "cell-8f6fd92582cdd37c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6bbfcdec866b29256af453c90b0fe690",
     "grade": true,
     "grade_id": "cell-5c46c2c4a270da3e",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# these tests are worth 3 marks \n",
    "gdtest = gradientDescent(grad, [0.3,0.4], 0.01, 2)\n",
    "assert gdtest.shape == (3,2)\n",
    "assert numpy.isclose(gdtest, numpy.array([\n",
    "        [ 0.3       ,  0.4       ],\n",
    "        [ 0.686     , -0.22      ],\n",
    "        [-1.20271542,  1.161192  ]])).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb1f474a87b30ba1f72dc227b63f8c2e",
     "grade": false,
     "grade_id": "cell-29737c69afdb16ea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Plotting task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "49437bb45a822935fbcdd2776d1a80b5",
     "grade": false,
     "grade_id": "cell-11b8d20f2cd67bdd",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "Create a plot to show the trajectory of the gradient descent optimisation algorithm for different values of $\\eta$. Use the values of $\\eta$ provided. Start all trajectories at $r_0=(0.2,1)$. [3 marks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate banana function\n",
    "N = 100 # Resolution of 2D image\n",
    "x0 = -0.2\n",
    "x1 = 1.2\n",
    "y0 = 0\n",
    "y1 = 1.2\n",
    "xs = numpy.linspace(x0, x1, N)\n",
    "ys = numpy.linspace(y0, y1, N)\n",
    "dat = numpy.zeros((N, N))\n",
    "\n",
    "for ix, x in enumerate(xs):\n",
    "    for iy, y in enumerate(ys):\n",
    "        r = [x,y]\n",
    "        dat[iy, ix] = f(r)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "im = plt.imshow(dat, extent=(x0, x1, y0, y1), origin='lower', cmap=matplotlib.cm.gray, \n",
    "                norm=matplotlib.colors.LogNorm(vmin=0.01, vmax=200))\n",
    "plt.colorbar(im, orientation='vertical', fraction=0.03925, pad=0.04)\n",
    "\n",
    "# Now generate the trajectories:\n",
    "gammas = [0.004, 0.003, 0.002]  # Gammas to try out\n",
    "r0 = numpy.array([0.2, 1])  # Initial seed point\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3d9582b53ccaed06fc92fbd1fda448f",
     "grade": false,
     "grade_id": "question",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Which of the three step size $\\eta$ is best? Use the box below to justify your answer. [2 marks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5b0fae38aac14c7fbfeb5e48965c421",
     "grade": true,
     "grade_id": "cell-fde1d40eb9bbabde",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
